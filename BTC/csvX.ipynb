{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGyCZg2JQeMAtrqdawwnJb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"sE25ByNZmDz2","executionInfo":{"status":"ok","timestamp":1740517750996,"user_tz":480,"elapsed":5720,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import yfinance as yf\n","from transformers import pipeline\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","import joblib\n","from datetime import datetime, timedelta\n","\n"]},{"cell_type":"code","source":["# Step 1: Download Bitcoin Price Data\n","def download_btc_price(start_date, end_date):\n","    btc = yf.download(\"BTC-USD\", start=start_date, end=end_date)\n","    return btc[[\"Close\"]]"],"metadata":{"id":"riF4N4KB8UTY","executionInfo":{"status":"ok","timestamp":1740517783051,"user_tz":480,"elapsed":8,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Step 2: Load Tweets from CSV\n","def load_tweets_from_csv(file_path):\n","    posts_df = pd.read_csv(file_path, low_memory=False)  # Handle large files\n","    # Adjust column names based on Kaggle dataset\n","    posts_df[\"timestamp\"] = pd.to_datetime(posts_df[\"date\"])  # 'date' is typical in this dataset\n","    posts_df[\"text\"] = posts_df[\"text\"].astype(str)  # Ensure text column is string\n","    return posts_df"],"metadata":{"id":"t2-fNwmk8UbV","executionInfo":{"status":"ok","timestamp":1740517799317,"user_tz":480,"elapsed":403,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Step 3: Sentiment Analysis\n","def analyze_sentiment(posts_df):\n","    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n","    # Apply sentiment analysis (may take time for large datasets; consider sampling)\n","    posts_df[\"sentiment\"] = posts_df[\"text\"].apply(\n","        lambda x: sentiment_analyzer(x[:512])[0][\"score\"] if sentiment_analyzer(x[:512])[0][\"label\"] == \"POSITIVE\" else -sentiment_analyzer(x[:512])[0][\"score\"]\n","    )  # Truncate to 512 chars for BERT\n","    return posts_df"],"metadata":{"id":"oN0iYWhy8Uec","executionInfo":{"status":"ok","timestamp":1740517820990,"user_tz":480,"elapsed":321,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Step 4: Prepare Data for DNN\n","def prepare_data(price_df, posts_df, seq_length=7):\n","    posts_df[\"date\"] = posts_df[\"timestamp\"].dt.date\n","    daily_sentiment = posts_df.groupby(\"date\")[\"sentiment\"].mean()\n","    data = pd.merge(price_df, daily_sentiment, left_index=True, right_index=True, how=\"inner\")\n","    scaler = MinMaxScaler()\n","    scaled_data = scaler.fit_transform(data[[\"Close\", \"sentiment\"]])\n","    X, y = [], []\n","    for i in range(len(scaled_data) - seq_length):\n","        X.append(scaled_data[i:i + seq_length])\n","        y.append(scaled_data[i + seq_length, 0])\n","    return np.array(X), np.array(y), scaler, data"],"metadata":{"id":"KcR7PlPD8Ug_","executionInfo":{"status":"ok","timestamp":1740517837014,"user_tz":480,"elapsed":449,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Step 5: Build and Train LSTM Model\n","def build_and_train_model(X, y):\n","    model = Sequential([\n","        LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n","        LSTM(32),\n","        Dense(1)\n","    ])\n","    model.compile(optimizer=\"adam\", loss=\"mse\")\n","    model.fit(X, y, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n","    return model"],"metadata":{"id":"2JVSZm6o8oMI","executionInfo":{"status":"ok","timestamp":1740517849102,"user_tz":480,"elapsed":364,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Main Execution\n","if __name__ == \"__main__\":\n","    # Define time range (adjust to match your CSV data; this is an example)\n","    end_date = datetime(2025, 2, 25)\n","    start_date = end_date - timedelta(days=30)\n","\n","    # Download Bitcoin price data\n","    price_df = download_btc_price(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\"))\n","    # Mount Google Drive (run this first in Colab)\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    # Load tweets from Kaggle CSV\n","    file_path = \"/content/drive/My Drive/Colab Notebooks/bitcoin_pred/BitcoinTweets.csv\"  # Update if filename differs after download\n","    posts_df = load_tweets_from_csv(file_path)\n","\n","    # Optional: Sample if too large (e.g., first 10,000 rows for speed)\n","    posts_df = posts_df.sample(n=10000, random_state=42) if len(posts_df) > 10000 else posts_df\n","\n","    # Process sentiment\n","    print(\"Analyzing sentiment (this may take a while)...\")\n","    posts_df = analyze_sentiment(posts_df)\n","\n","    # Prepare data\n","    X, y, scaler, data = prepare_data(price_df, posts_df)\n","\n","    # Train and save model\n","    model = build_and_train_model(X, y)\n","    model.save(\"btc_model.h5\")\n","    joblib.dump(scaler, \"scaler.pkl\")\n","    print(\"Model trained and saved as 'btc_model.h5'; Scaler saved as 'scaler.pkl'\")\n","\n","    # Test prediction with old data\n","    last_sequence = scaler.transform(data.tail(7)[[\"Close\", \"sentiment\"]])\n","    last_sequence = last_sequence.reshape(1, 7, 2)\n","    prediction = model.predict(last_sequence)\n","    dummy = np.zeros((1, 2))\n","    dummy[0, 0] = prediction[0]\n","    predicted_price = scaler.inverse_transform(dummy)[0, 0]\n","    print(f\"Test prediction with old data for Feb 26, 2025: ${predicted_price:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"81bR5t2o8rNv","executionInfo":{"status":"error","timestamp":1740517925163,"user_tz":480,"elapsed":930,"user":{"displayName":"Alireza Ebrahimi","userId":"13337172735206414558"}},"outputId":"0e83605e-6184-441b-da16-1afec27fa41c"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'datetime' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fa518731cf54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Define time range (adjust to match your CSV data; this is an example)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"]}]}]}